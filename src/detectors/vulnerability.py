"""
Vulnerability detection utilities for Movery
"""
import os
from typing import Dict, List, Optional, Set, Tuple, Any
import re
import difflib
import json
import logging
from abc import ABC, abstractmethod
from dataclasses import dataclass
import hashlib
from collections import defaultdict

from ..config.config import config
from ..utils.logging import get_logger
from ..utils.memory import MemoryMappedFile, cache
from ..analyzers.language import LanguageAnalyzerFactory

logger = get_logger(__name__)

@dataclass
class VulnerabilitySignature:
    """Vulnerability signature"""
    id: str
    name: str
    description: str
    severity: str
    cwe_id: Optional[str]
    cve_id: Optional[str]
    affected_languages: List[str]
    code_patterns: List[str]
    fix_patterns: List[str]
    context_patterns: List[str]
    
    @classmethod
    def from_dict(cls, data: Dict) -> "VulnerabilitySignature":
        """Create signature from dictionary"""
        return cls(
            id=data["id"],
            name=data["name"],
            description=data.get("description", ""),
            severity=data.get("severity", "UNKNOWN"),
            cwe_id=data.get("cwe_id"),
            cve_id=data.get("cve_id"),
            affected_languages=data.get("affected_languages", []),
            code_patterns=data.get("code_patterns", []),
            fix_patterns=data.get("fix_patterns", []),
            context_patterns=data.get("context_patterns", [])
        )
        
    def to_dict(self) -> Dict:
        """Convert signature to dictionary"""
        return {
            "id": self.id,
            "name": self.name,
            "description": self.description,
            "severity": self.severity,
            "cwe_id": self.cwe_id,
            "cve_id": self.cve_id,
            "affected_languages": self.affected_languages,
            "code_patterns": self.code_patterns,
            "fix_patterns": self.fix_patterns,
            "context_patterns": self.context_patterns
        }

@dataclass
class VulnerabilityMatch:
    """Vulnerability match result"""
    signature: VulnerabilitySignature
    file: str
    line_start: int
    line_end: int
    matched_code: str
    confidence: float
    context: Dict[str, Any]
    
    def to_dict(self) -> Dict:
        """Convert match to dictionary"""
        return {
            "signature": self.signature.to_dict(),
            "file": self.file,
            "line_start": self.line_start,
            "line_end": self.line_end,
            "matched_code": self.matched_code,
            "confidence": self.confidence,
            "context": self.context
        }

class VulnerabilityDetector(ABC):
    """Base class for vulnerability detectors"""
    
    def __init__(self):
        self.signatures: List[VulnerabilitySignature] = []
        
    @abstractmethod
    def load_signatures(self, signature_file: str):
        """Load vulnerability signatures"""
        pass
        
    @abstractmethod
    def detect(self, file: str) -> List[VulnerabilityMatch]:
        """Detect vulnerabilities in file"""
        pass
        
    @abstractmethod
    def analyze_context(self, match: VulnerabilityMatch) -> Dict:
        """Analyze context of vulnerability match"""
        pass

class PatternMatcher:
    """Pattern matching utility"""
    
    @staticmethod
    def match_pattern(code: str, pattern: str) -> Optional[Tuple[int, int]]:
        """Match pattern in code and return line range"""
        try:
            regex = re.compile(pattern, re.MULTILINE)
            match = regex.search(code)
            if match:
                start = code.count("\n", 0, match.start()) + 1
                end = code.count("\n", 0, match.end()) + 1
                return start, end
        except re.error as e:
            logger.error(f"Invalid pattern {pattern}: {str(e)}")
        return None
        
    @staticmethod
    def extract_context(code: str, line_start: int, line_end: int,
                       context_lines: int = 3) -> str:
        """Extract context around matched lines"""
        lines = code.splitlines()
        start = max(0, line_start - context_lines - 1)
        end = min(len(lines), line_end + context_lines)
        return "\n".join(lines[start:end])

class ASTMatcher:
    """AST-based pattern matching"""
    
    def __init__(self):
        self.analyzers = LanguageAnalyzerFactory._analyzers
        
    def match_ast_pattern(self, ast_node: Any, pattern: Dict) -> bool:
        """Match pattern against AST node"""
        if not isinstance(pattern, dict):
            return False
            
        node_type = pattern.get("type")
        if not node_type:
            return False
            
        if not isinstance(ast_node, getattr(ast, node_type, None)):
            return False
            
        for key, value in pattern.items():
            if key == "type":
                continue
                
            if not hasattr(ast_node, key):
                return False
                
            node_value = getattr(ast_node, key)
            
            if isinstance(value, dict):
                if not self.match_ast_pattern(node_value, value):
                    return False
            elif isinstance(value, list):
                if not isinstance(node_value, list):
                    return False
                if len(value) != len(node_value):
                    return False
                for pattern_item, node_item in zip(value, node_value):
                    if isinstance(pattern_item, dict):
                        if not self.match_ast_pattern(node_item, pattern_item):
                            return False
                    elif pattern_item != node_item:
                        return False
            elif value != node_value:
                return False
                
        return True

class SemanticMatcher:
    """Semantic pattern matching"""
    
    def __init__(self):
        self.cache = {}
        
    def get_semantic_hash(self, code: str) -> str:
        """Generate semantic hash of code"""
        # Remove comments
        code = re.sub(r"#.*$", "", code, flags=re.MULTILINE)
        code = re.sub(r"//.*$", "", code, flags=re.MULTILINE)
        code = re.sub(r"/\*.*?\*/", "", code, flags=re.DOTALL)
        
        # Normalize whitespace
        code = re.sub(r"\s+", " ", code)
        code = code.strip()
        
        # Remove string literals
        code = re.sub(r'"[^"]*"', '""', code)
        code = re.sub(r"'[^']*'", "''", code)
        
        # Normalize variable names
        var_counter = 0
        var_map = {}
        
        def replace_var(match):
            nonlocal var_counter
            var = match.group(0)
            if var not in var_map:
                var_map[var] = f"var{var_counter}"
                var_counter += 1
            return var_map[var]
            
        code = re.sub(r"\b[a-zA-Z_]\w*\b", replace_var, code)
        
        # Generate hash
        return hashlib.sha256(code.encode()).hexdigest()
        
    def match_semantic(self, code1: str, code2: str,
                      threshold: float = 0.8) -> float:
        """Calculate semantic similarity between two code snippets"""
        hash1 = self.get_semantic_hash(code1)
        hash2 = self.get_semantic_hash(code2)
        
        cache_key = f"{hash1}:{hash2}"
        if cache_key in self.cache:
            return self.cache[cache_key]
            
        # Calculate similarity
        s = difflib.SequenceMatcher(None, code1, code2)
        similarity = s.ratio()
        
        self.cache[cache_key] = similarity
        return similarity

class DefaultVulnerabilityDetector(VulnerabilityDetector):
    """Default implementation of vulnerability detector"""
    
    def __init__(self):
        super().__init__()
        self.pattern_matcher = PatternMatcher()
        self.ast_matcher = ASTMatcher()
        self.semantic_matcher = SemanticMatcher()
        
    def load_signatures(self, signature_file: str):
        """Load vulnerability signatures from file"""
        with open(signature_file, "r") as f:
            data = json.load(f)
            self.signatures = [
                VulnerabilitySignature.from_dict(sig)
                for sig in data.get("signatures", [])
            ]
            
    def detect(self, file: str) -> List[VulnerabilityMatch]:
        """Detect vulnerabilities in file"""
        matches = []
        
        # Get file extension and check if we support it
        ext = os.path.splitext(file)[1].lower()
        analyzer = LanguageAnalyzerFactory.get_analyzer(file)
        if not analyzer:
            logger.warning(f"No analyzer found for file {file}")
            return matches
            
        # Read file content
        try:
            with open(file, "r", encoding="utf-8") as f:
                content = f.read()
        except Exception as e:
            logger.error(f"Error reading file {file}: {str(e)}")
            return matches
            
        # Try to parse AST
        try:
            ast_node = analyzer.parse_file(file)
        except Exception as e:
            logger.error(f"Error parsing file {file}: {str(e)}")
            ast_node = None
            
        # Check each signature
        for sig in self.signatures:
            # Skip if language not supported
            if ext[1:] not in sig.affected_languages:
                continue
                
            # Try pattern matching
            for pattern in sig.code_patterns:
                match_range = self.pattern_matcher.match_pattern(content, pattern)
                if match_range:
                    line_start, line_end = match_range
                    matched_code = self.pattern_matcher.extract_context(
                        content, line_start, line_end)
                        
                    # Calculate confidence
                    confidence = 0.5  # Base confidence from pattern match
                    
                    # Add semantic matching confidence if enabled
                    if config.detector.enable_semantic_match:
                        for fix_pattern in sig.fix_patterns:
                            semantic_conf = self.semantic_matcher.match_semantic(
                                matched_code, fix_pattern)
                            confidence = max(confidence,
                                          semantic_conf * 0.8)  # Weight semantic less
                                          
                    # Add AST matching confidence if enabled
                    if config.detector.enable_syntax_match and ast_node:
                        # TODO: Implement AST pattern matching
                        pass
                        
                    match = VulnerabilityMatch(
                        signature=sig,
                        file=file,
                        line_start=line_start,
                        line_end=line_end,
                        matched_code=matched_code,
                        confidence=confidence,
                        context={}
                    )
                    
                    # Analyze context
                    match.context = self.analyze_context(match)
                    
                    matches.append(match)
                    
        return matches
        
    def analyze_context(self, match: VulnerabilityMatch) -> Dict:
        """Analyze context of vulnerability match"""
        context = {
            "imports": [],
            "functions": [],
            "classes": [],
            "variables": []
        }
        
        analyzer = LanguageAnalyzerFactory.get_analyzer(match.file)
        if not analyzer:
            return context
            
        try:
            ast_node = analyzer.parse_file(match.file)
            context["imports"] = analyzer.get_imports(ast_node)
            context["functions"] = analyzer.get_functions(ast_node)
            context["classes"] = analyzer.get_classes(ast_node)
            context["variables"] = analyzer.get_variables(ast_node)
        except Exception as e:
            logger.error(f"Error analyzing context: {str(e)}")
            
        return context

# Global detector instance
detector = DefaultVulnerabilityDetector() 